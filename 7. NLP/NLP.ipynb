{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1N-5kDq3yPOFBlJ5Mq4u1U9LPkH3ox1EB","authorship_tag":"ABX9TyMTz2z1l3wMkIfY78GvBXaY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NLP Tools"],"metadata":{"id":"9PjnTzrYW5WA"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dI0hGQqHWzUy","executionInfo":{"status":"ok","timestamp":1666168182944,"user_tz":-420,"elapsed":52096,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"f9370608-fc9d-428a-bf71-279923ee495f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n","\u001b[K     |████████████████████████████████| 281.3 MB 50 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.5\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 55.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=f75335be5f8bb02fa14f9f55cec96c3fef54540ca88c7084eb6bc5c530ae10ee\n","  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"id":"8CEjkcfpW-xP","executionInfo":{"status":"ok","timestamp":1666168213781,"user_tz":-420,"elapsed":389,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName('nlp').getOrCreate()"],"metadata":{"id":"IAzBngTJXUyq","executionInfo":{"status":"ok","timestamp":1666168318874,"user_tz":-420,"elapsed":6691,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Tokenizer"],"metadata":{"id":"6l9Rbg9pXt1A"}},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer, RegexTokenizer\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"metadata":{"id":"6iP3HI8KXs9Z","executionInfo":{"status":"ok","timestamp":1666168429852,"user_tz":-420,"elapsed":6,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["sentenceDataFrame = spark.createDataFrame([\n","    (0, \"Hi I heard about Spark\"),\n","    (1, \"I wish Java could use case classes\"),\n","    (2, \"Logistic,regression,models,are,neat\")\n","], [\"id\", \"sentence\"])\n","\n","sentenceDataFrame.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUNUZR14YAAI","executionInfo":{"status":"ok","timestamp":1666168451998,"user_tz":-420,"elapsed":7509,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"43b4271c-6a90-4450-9da5-486b84d498e2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|Hi I heard about ...|\n","|  1|I wish Java could...|\n","|  2|Logistic,regressi...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n","regexTokenizer = RegexTokenizer(inputCol='sentence', outputCol='words', pattern='\\\\W')\n","\n","countToken = udf(lambda words: len(words), IntegerType())\n","\n","tokenized = tokenizer.transform(sentenceDataFrame)\n","tokenized.select('sentence', 'words').withColumn('tokens', countToken(col('words'))).show(truncate=False)\n","\n","regexTokenized = regexTokenizer.transform(sentenceDataFrame)\n","regexTokenized.select('sentence', 'words').withColumn('tokens', countToken(col('words'))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxAUAxYqYNLn","executionInfo":{"status":"ok","timestamp":1666168808618,"user_tz":-420,"elapsed":3240,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"c5eeadc3-fdeb-4af3-bfcc-8bc52f829a1f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------+------------------------------------------+------+\n","|sentence                           |words                                     |tokens|\n","+-----------------------------------+------------------------------------------+------+\n","|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n","|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n","|Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |\n","+-----------------------------------+------------------------------------------+------+\n","\n","+-----------------------------------+------------------------------------------+------+\n","|sentence                           |words                                     |tokens|\n","+-----------------------------------+------------------------------------------+------+\n","|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n","|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n","|Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |\n","+-----------------------------------+------------------------------------------+------+\n","\n"]}]},{"cell_type":"markdown","source":["## Stopwords Removal"],"metadata":{"id":"nWrGwRx1ZoTv"}},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover\n","\n","sentenceData = spark.createDataFrame([\n","    (0, [\"I\", \"saw\", \"the\", \"red\", \"balloon\"]),\n","    (1, [\"Mary\", \"had\", \"a\", \"little\", \"lamb\"])\n","], [\"id\", \"raw\"])\n","\n","remover = StopWordsRemover(inputCol='raw', outputCol='filtered')\n","remover.transform(sentenceData).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzbefmO8ZlXj","executionInfo":{"status":"ok","timestamp":1666169004437,"user_tz":-420,"elapsed":979,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"764ca243-e37f-4270-ed0b-bc879cb30e25"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+----------------------------+--------------------+\n","|id |raw                         |filtered            |\n","+---+----------------------------+--------------------+\n","|0  |[I, saw, the, red, balloon] |[saw, red, balloon] |\n","|1  |[Mary, had, a, little, lamb]|[Mary, little, lamb]|\n","+---+----------------------------+--------------------+\n","\n"]}]},{"cell_type":"markdown","source":["## n-grams"],"metadata":{"id":"UokE5ad0aYCG"}},{"cell_type":"code","source":["from pyspark.ml.feature import NGram\n","\n","wordDataFrame = spark.createDataFrame([\n","    (0, [\"Hi\", \"I\", \"heard\", \"about\", \"Spark\"]),\n","    (1, [\"I\", \"wish\", \"Java\", \"could\", \"use\", \"case\", \"classes\"]),\n","    (2, [\"Logistic\", \"regression\", \"models\", \"are\", \"neat\"])\n","], [\"id\", \"words\"])\n","\n","ngram = NGram(inputCol='words', outputCol='ngrams')\n","ngramDataFrame = ngram.transform(wordDataFrame)\n","ngramDataFrame.select('ngrams').show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qo0EDSbbaN5g","executionInfo":{"status":"ok","timestamp":1666169144586,"user_tz":-420,"elapsed":936,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"e26c48be-8e08-4332-d69c-0117d0d6ff83"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------+\n","|ngrams                                                            |\n","+------------------------------------------------------------------+\n","|[Hi I, I heard, heard about, about Spark]                         |\n","|[I wish, wish Java, Java could, could use, use case, case classes]|\n","|[Logistic regression, regression models, models are, are neat]    |\n","+------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["# Feature Extractor"],"metadata":{"id":"rjGS7-uga94-"}},{"cell_type":"markdown","source":["## TF-IDF"],"metadata":{"id":"mJokFaH2bDGZ"}},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n","\n","sentenceData = spark.createDataFrame([\n","    (0.0, \"Hi I heard about Spark\"),\n","    (0.0, \"I wish Java could use case classes\"),\n","    (1.0, \"Logistic regression models are neat\")\n","], [\"label\", \"sentence\"])\n","\n","sentenceData.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3ahHrVLa3su","executionInfo":{"status":"ok","timestamp":1666169240053,"user_tz":-420,"elapsed":547,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"1c94f529-a61e-4f80-918c-0e4041aab4f1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------------------+\n","|label|            sentence|\n","+-----+--------------------+\n","|  0.0|Hi I heard about ...|\n","|  0.0|I wish Java could...|\n","|  1.0|Logistic regressi...|\n","+-----+--------------------+\n","\n"]}]},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","wordsData = tokenizer.transform(sentenceData)\n","wordsData.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-aROAVrcPaC","executionInfo":{"status":"ok","timestamp":1666169504687,"user_tz":-420,"elapsed":870,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"5ecf9972-6425-4e89-ed6d-07f65e8679c1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------------------+--------------------+\n","|label|            sentence|               words|\n","+-----+--------------------+--------------------+\n","|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n","|  0.0|I wish Java could...|[i, wish, java, c...|\n","|  1.0|Logistic regressi...|[logistic, regres...|\n","+-----+--------------------+--------------------+\n","\n"]}]},{"cell_type":"code","source":["hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=20)\n","featurizedData = hashingTF.transform(wordsData)\n","\n","idf = IDF(inputCol='rawFeatures', outputCol='features')\n","idfModel = idf.fit(featurizedData)\n","rescaleData = idfModel.transform(featurizedData)\n","\n","rescaleData.select('label', 'features').show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAV4URLAbPW1","executionInfo":{"status":"ok","timestamp":1666169559004,"user_tz":-420,"elapsed":966,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"679c8a8e-bf34-4d8f-e828-68a917dc30af"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------------------+\n","|label|            features|\n","+-----+--------------------+\n","|  0.0|(20,[6,8,13,16],[...|\n","|  0.0|(20,[0,2,7,13,15,...|\n","|  1.0|(20,[3,4,6,11,19]...|\n","+-----+--------------------+\n","\n"]}]},{"cell_type":"markdown","source":["## CountVectorizer"],"metadata":{"id":"EmJbpebVuA4I"}},{"cell_type":"code","source":["from pyspark.ml.feature import CountVectorizer\n","\n","# Input data: Each row is a bag of words with a ID.\n","df = spark.createDataFrame([\n","    (0, \"a b c\".split(\" \")),\n","    (1, \"a b b c a\".split(\" \"))\n","], [\"id\", \"words\"])\n","\n","# fit a CountVectorizerModel from the corpus.\n","cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=3, minDF=2.0)\n","\n","model = cv.fit(df)\n","\n","result = model.transform(df)\n","result.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhrjGKuXcG-F","executionInfo":{"status":"ok","timestamp":1666174193448,"user_tz":-420,"elapsed":2084,"user":{"displayName":"Billy Beniar","userId":"09162447057350350594"}},"outputId":"84801df4-85dd-4265-c521-ad2cff37e309"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------+-------------------------+\n","|id |words          |features                 |\n","+---+---------------+-------------------------+\n","|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n","|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|\n","+---+---------------+-------------------------+\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mLRq6AHcuITj"},"execution_count":null,"outputs":[]}]}